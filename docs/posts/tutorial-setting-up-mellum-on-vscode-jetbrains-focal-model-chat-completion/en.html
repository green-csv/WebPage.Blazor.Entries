<h1 id="contents">Contents</h1>
<ul>
<li><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#tutorial-setting-up-and-running-mellum">Tutorial: Setting Up and Running Mellum</a></li>
<li><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#add-mellum-to-ollama">Add Mellum to Ollama</a></li>
<li><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#vs-code-continue--ollama">VS Code, Continue &#x26; Ollama</a></li>
</ul>
<h1 id="tutorial-setting-up-and-running-mellum">Tutorial: Setting Up and Running Mellum</h1>
<ol>
<li>Clone the Mellum model files</li>
</ol>
<pre><code class="hljs language-bash">   git <span class="hljs-built_in">clone</span> https://huggingface.co/JetBrains/Mellum-4b-base-gguf
</code></pre>
<p>(~4.5 GB)<sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></p>
<ol start="2">
<li>
<p>Install Ollama<sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>
Download and install the appropriate Ollama package for your OS (Ollama, 2025).</p>
</li>
<li>
<p>Install Continue<sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup> in VS Code
Add the Continue extension to wire up Mellum via Ollama.</p>
</li>
</ol>
<h1 id="add-mellum-to-ollama">Add Mellum to Ollama</h1>
<ol>
<li>In your project directory, create a file named <code>Modelfile</code> with:</li>
</ol>
<pre><code class="hljs language-text">FROM ./mellum-4b-base.Q8_0.gguf
# PARAMETER &#x3C;parameter> &#x3C;value>

SYSTEM "You are a completion assistant. Predict the most likely continuation of the given input accurately and concisely."

PARAMETER temperature      0.2
PARAMETER top_p            0.9
PARAMETER top_k            40
PARAMETER repeat_penalty   1.2
PARAMETER repeat_last_n    128
PARAMETER num_predict      512
PARAMETER num_ctx          8192

PARAMETER stop "###"
PARAMETER stop "\n\n"

</code></pre>
<p>All of these directives and parameters come from the Ollama Modelfile<sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup></p>
<ol start="2">
<li>(Optional) To run a quantized build on modest hardware at the expense of some accuracy, see Ollama’s quantization guide:</li>
</ol>
<blockquote>
<p><a href="https://ollama.readthedocs.io/en/import/#quantizing-a-model">https://ollama.readthedocs.io/en/import/#quantizing-a-model</a></p>
</blockquote>
<ol start="3">
<li>Create your Ollama model</li>
</ol>
<pre><code class="hljs language-pws">ollama create Mellum -f .\Modelfile`
</code></pre>
<p>Make sure the <code>FROM</code> base matches the one used to the Model file (Chang, n.d.).</p>
<ol start="4">
<li>Inspect default values</li>
</ol>
<pre><code>ollama show Mellum
</code></pre>
<p>You’ll see something like:</p>
<pre><code> Model
    architecture        llama
    parameters          4.0B
    context length      8192
    embedding length    3072
    quantization        Q8_0

  Capabilities
    completion

  Parameters
    top_k             40
    top_p             0.9
    num_ctx           8192
    num_predict       512
    repeat_last_n     128
    repeat_penalty    1.2
    stop              "###"
    stop              "\n\n"
    temperature       0.2

</code></pre>
<p>Tweak any settings in your <code>Modelfile</code>, then rebuild with <code>ollama create</code> as above.</p>
<h1 id="vs-code-continue--ollama">VS Code, Continue &#x26; Ollama</h1>
<p><strong>Continue</strong><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-10" id="user-content-fnref-10-2" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup> lets you hook any local or remote model into VS Code, select Ollama as your provider, then Add a Local Model even though it isn’t in the Ollama registry by default. Configure per-context assistants from the Continue UI, and you’ll get Mellum focal context completions right in VS Code.</p>
<p><img src="https://entries.greencsv.dev/media/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion/img-20250522093033.png" alt="Continue configuration for Ollama + Mellum "></p>
<p>Overall, on my station with a dedicated GPU it’s fast, but on smaller machines you can quantize the model to fit your needs. Now I can zip between Unity and VS Code with context-aware completions via Mellum.</p>
<p>In continue configured for each context available a here are some insights</p>
<div>
<video controls width="100%" alt="Mellum Context completion" src="https://entries.greencsv.dev/media/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion/GameManager.mp4">
  Your browser doesn’t support video.
</video>
</div>
<div> 
<video controls width="100%" alt="Mellum Instructions" src="https://entries.greencsv.dev/media/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion/ShiInputManager.mp4">
  Your browser doesn’t support video.
</video>
</div>
<p><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-1" id="user-content-fnref-1-2" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-3" id="user-content-fnref-3-2" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-7" id="user-content-fnref-7-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref="" aria-describedby="footnote-label">9</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-9" id="user-content-fnref-9" data-footnote-ref="" aria-describedby="footnote-label">10</a></sup><sup><a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fn-10" id="user-content-fnref-10-3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-3">
<p>JetBrains. (2025b, April). Mellum goes open source: A purpose‐built LLM for developers, now on Hugging Face. <em>JetBrains Blog.</em> Retrieved May 21, 2025, from <a href="https://blog.jetbrains.com/ai/2025/04/mellum-goes-open-source-a-purpose-built-llm-for-developers-now-on-hugging-face/">https://blog.jetbrains.com/ai/2025/04/mellum-goes-open-source-a-purpose-built-llm-for-developers-now-on-hugging-face/</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-3-2" data-footnote-backref="" aria-label="Back to reference 1-2" class="data-footnote-backref">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-7">
<p>Ollama. (2025). Download Ollama on Windows [Software]. Retrieved May 21, 2025, from <a href="https://ollama.com/download/windows">https://ollama.com/download/windows</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-7" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-7-2" data-footnote-backref="" aria-label="Back to reference 2-2" class="data-footnote-backref">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-10">
<p>Continue.dev. (2025). <em>Continue – Open-source AI code assistant</em> [Extension]. Visual Studio Marketplace. Retrieved May 21, 2025, from <a href="https://marketplace.visualstudio.com/items?itemName=Continue.continue">https://marketplace.visualstudio.com/items?itemName=Continue.continue</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-10" data-footnote-backref="" aria-label="Back to reference 3" class="data-footnote-backref">↩</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-10-2" data-footnote-backref="" aria-label="Back to reference 3-2" class="data-footnote-backref">↩<sup>2</sup></a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-10-3" data-footnote-backref="" aria-label="Back to reference 3-3" class="data-footnote-backref">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-1">
<p>Chang, L. (n.d.). <em>Model file specification Ollama</em> [Documentation]. GitHub. Retrieved May 21, 2025, from <a href="https://github.com/lloydchang/ollama-ollama/blob/main/docs/modelfile.md">https://github.com/lloydchang/ollama-ollama/blob/main/docs/modelfile.md</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 4" class="data-footnote-backref">↩</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-1-2" data-footnote-backref="" aria-label="Back to reference 4-2" class="data-footnote-backref">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-2">
<p>JetBrains. (2025a, February). Why and how JetBrains built Mellum – the LLM designed for code completion. <em>JetBrains Blog.</em> Retrieved May 21, 2025, from <a href="https://blog.jetbrains.com/ai/2025/02/why-and-how-jetbrains-built-mellum-the-llm-designed-for-code-completion/">https://blog.jetbrains.com/ai/2025/02/why-and-how-jetbrains-built-mellum-the-llm-designed-for-code-completion/</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 5" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>JetBrains. (2025c, April 8). <em>JetBrains Mellum overview &#x26; usage</em> [IDE Services documentation]. Retrieved May 21, 2025, from <a href="https://www.jetbrains.com/help/ide-services/jetbrains-mellum.html">https://www.jetbrains.com/help/ide-services/jetbrains-mellum.html</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 6" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>JetBrains. (2025d, May). JetBrains AI Assistant – now in Visual Studio Code. <em>JetBrains Blog.</em> Retrieved May 21, 2025, from <a href="https://blog.jetbrains.com/ai/2025/05/jetbrains-ai-assistant-now-in-visual-studio-code/">https://blog.jetbrains.com/ai/2025/05/jetbrains-ai-assistant-now-in-visual-studio-code/</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 7" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-6">
<p>JetBrains. (2025e). <em>Mellum-4b-base-gguf</em> [Model]. Hugging Face. Retrieved May 21, 2025, from <a href="https://huggingface.co/JetBrains/Mellum-4b-base-gguf">https://huggingface.co/JetBrains/Mellum-4b-base-gguf</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-6" data-footnote-backref="" aria-label="Back to reference 8" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>YouTube. (n.d.). <em>How To Make a 3D Space Shooter Game in Unity – Tutorial</em> [Video]. YouTube. Retrieved May 21, 2025, from <a href="https://www.youtube.com/watch?v=VW3PkEF1Fzk">https://www.youtube.com/watch?v=VW3PkEF1Fzk</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-8" data-footnote-backref="" aria-label="Back to reference 9" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-9">
<p>JetBrains. (2025f, May). <em>ReSharper for Visual Studio Code</em> [Extension]. Visual Studio Marketplace. Retrieved May 21, 2025, from <a href="https://marketplace.visualstudio.com/items?itemName=jetbrains.resharper-code">https://marketplace.visualstudio.com/items?itemName=jetbrains.resharper-code</a> <a href="entry/tutorial-setting-up-mellum-on-vscode-jetbrains-focal-model-chat-completion#user-content-fnref-9" data-footnote-backref="" aria-label="Back to reference 10" class="data-footnote-backref">↩</a></p>
</li>
</ol>
</section>